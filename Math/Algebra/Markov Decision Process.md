### $P(s'|s,a)$
probability of moving to state $s'$ when taking action $a$ in state $s$
**Markov** means future only depends on current state
- $S$ set of states
- $A$ set of actions
- $R(s,a)$ reward after taking action $a$ in state $s$
- $\lambda$ discount factor $0\leq\lambda<1$, how much future rewards are worth compared to immediate ones

- Measures surprise after finding out true distribution is $P$ when you assumed it was $Q$
- Measured in bits of information gained, or other [[Entropy]] units
- Specifically it gives average extra info needed to correct your assumption
### Formula $D_{KL}(P||Q)=\sum_x P(x)\log\frac{P(x)}{Q(x)}$
